{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.utils import pprint\n",
    "twitter = Twitter()\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('max_colwidth', 500)\n",
    "\n",
    "common_front = '../../dataset/go_0715/gogosing_' \n",
    "common_back = '.json'\n",
    "\n",
    "def get_file(file_num):   \n",
    "    file_path = common_front + str(file_num) + common_back\n",
    "    json_data = open(file_path).read()\n",
    "    data = json.loads(json_data)\n",
    "    df_data = pd.DataFrame(data)\n",
    "    return df_data\n",
    "\n",
    "\n",
    "# 74번 파일이 에러가 나서 제외함\n",
    "def concat_file(file_num):\n",
    "    start_file = pd.DataFrame(get_file(1))\n",
    "    for i in range(2,file_num+1):\n",
    "        if( i == 74):\n",
    "            continue\n",
    "        df_tmp = pd.DataFrame(get_file(i))\n",
    "        start_file = pd.concat([start_file, df_tmp])\n",
    "    start_file = start_file.reset_index(drop=True)\n",
    "    return start_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go_data = concat_file(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772829"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(go_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 소수점 아래 3자리까지 나타내기, 4째자리에서 반올림\n",
    "def short_float(val):\n",
    "    value = float(\"{:.4f}\".format(val))\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_group(title, groups, used_func):\n",
    "    pivot_num = 0.1\n",
    "    save_list = list()\n",
    "\n",
    "    pprint(title)\n",
    "    cur_num = 0.0\n",
    "    for i, group in enumerate(groups):\n",
    "        save_list.append(used_func(group))\n",
    "        print('group ' + str(i + 1) + ' = ' + str(float(\"{:.1f}\".format(cur_num))) + str(' over ') + str(\n",
    "            float(\"{:.1f}\".format(cur_num + pivot_num))) + str(' under : '), save_list[i])\n",
    "        cur_num += pivot_num\n",
    "    print('\\n')\n",
    "\n",
    "    return save_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "twitter=Twitter()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer : 문장에서 색인어 추출을 위해 정해진 품사의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "def tokenizer(raw, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\",\"Adjective\",\"KoreanParticle\",\n",
    "                        \"Punctuation\",\"Determiner\", \"Adverb\", \"Conjunction\",\"Excalmation\", \"Foreign\"], stopword=[]):\n",
    "    return [\n",
    "        word for word, tag in twitter.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "        \n",
    "          if len(word) > 1 and tag in pos and word not in stopword\n",
    "\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer,\n",
    "    min_df=1,\n",
    "    \n",
    "    sublinear_tf=True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "#reviewer의 desc를 담는 리스트\n",
    "def make_reviews(cid):\n",
    "    desc=(go_data.loc[go_data['cId']==cid])['desc']\n",
    "    desc=list(desc)\n",
    "    \n",
    "    return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. 리뷰들을 tf-idf 적용하여 벡터화\n",
    "def tfidf(desc):\n",
    "    X = vectorize.fit_transform(desc)\n",
    "    print('fit_transform, (No.review {}, feature {})'.format(X.shape[0], X.shape[1]))\n",
    "    features = vectorize.get_feature_names()\n",
    "    \n",
    "   # print (pd.DataFrame(data=X.toarray(), columns=features))\n",
    "    vector_array=X.toarray()\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. 유사도 구하기\n",
    "def similarity(vector_arr,desc):   \n",
    "    sm=[] #한 리뷰어의 리뷰 유사도를 담을 리스트\n",
    "    max_cnt=0 #리뷰 유사도 최대값이 0.6 이상 count\n",
    "    _sum=0\n",
    "    _mid=0\n",
    "    cnt=0\n",
    "    for i in range(len(desc)-1):\n",
    "        srch_vector= vectorize.transform([desc[i]])\n",
    "        for j in range(i+1, len(desc)):\n",
    "            cosine_similar =cosine_similarity(srch_vector, [vector_arr[j]]).flatten()\n",
    "            cosine_similar=short_float(float(cosine_similar))\n",
    "           # print (\"cosine_similar \") + str(i+1) + str(' 번째 리뷰와') + str(j+1) + str(' 번째 리뷰 : ') + str(cosine_similar)\n",
    "            sm.append(cosine_similar)\n",
    "\n",
    "\n",
    "    #pprint(u'유사도 리스트'),;print (sm)\n",
    "\n",
    "    sm=sm.sort()\n",
    "    _min=sm[0]\n",
    "    _max=sm[len(sm)-1]\n",
    "    _sum=sm[0]\n",
    "    \n",
    "    for i in range(1,len(sm)):\n",
    "        if(_min>sm[i]):\n",
    "            _min=sm[i]\n",
    "        if(_max<sm[i]):\n",
    "            _max=sm[i]\n",
    "        _sum+=sm[i]\n",
    "        if(sm[i]==1):\n",
    "            cnt+=1\n",
    "\n",
    "    if(_max>=0.9):\n",
    "        max_cnt+=1\n",
    "        \n",
    "    avg= short_float(_sum/len(sm))\n",
    "    \n",
    "    \n",
    "    print ('min : ', _min)\n",
    "    print('max : ', _max)\n",
    "    print('avg : ', avg)\n",
    "    print('num of 1 : ', cnt)\n",
    "    print('# max_cnt : ', max_cnt)\n",
    "    \n",
    "    return _max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_transform, (No.review 59, feature 598)\n",
      "  (0, 393)\t0.17352469413085644\n",
      "  (0, 575)\t0.27166635180125503\n",
      "  (0, 80)\t0.2038538983652817\n",
      "  (0, 504)\t0.27166635180125503\n",
      "  (0, 197)\t0.27166635180125503\n",
      "  (0, 84)\t0.19433886207292184\n",
      "  (0, 212)\t0.27166635180125503\n",
      "  (0, 71)\t0.27166635180125503\n",
      "  (0, 177)\t0.21510779767807126\n",
      "  (0, 455)\t0.16106900382984712\n",
      "  (0, 11)\t0.12652640863694853\n",
      "  (0, 375)\t0.27166635180125503\n",
      "  (0, 571)\t0.07549921475897794\n",
      "  (0, 36)\t0.3150888704988498\n",
      "  (0, 456)\t0.22888145726582043\n",
      "  (0, 107)\t0.27166635180125503\n",
      "  (0, 180)\t0.17882633946474294\n",
      "  (0, 52)\t0.09862737594477176\n",
      "  (0, 86)\t0.11334342872585511\n",
      "  (0, 594)\t0.27166635180125503\n",
      "  (1, 393)\t0.2500544070436689\n",
      "  (1, 52)\t0.2982654270173768\n",
      "  (1, 186)\t0.2183939160793078\n",
      "  (1, 273)\t0.355414066116991\n",
      "  (1, 139)\t0.39147954620310094\n",
      "  :\t:\n",
      "  (58, 591)\t0.09757815277382803\n",
      "  (58, 35)\t0.1021098200799417\n",
      "  (58, 0)\t0.1126359692895425\n",
      "  (58, 268)\t0.13432089960736557\n",
      "  (58, 469)\t0.11887084491847022\n",
      "  (58, 18)\t0.16451494284012302\n",
      "  (58, 21)\t0.14431710774858092\n",
      "  (58, 387)\t0.18471277793166513\n",
      "  (58, 560)\t0.1390686800100123\n",
      "  (58, 114)\t0.1021098200799417\n",
      "  (58, 236)\t0.10454025286016645\n",
      "  (58, 514)\t0.17700203438521458\n",
      "  (58, 23)\t0.10454025286016645\n",
      "  (58, 10)\t0.17359710715985818\n",
      "  (58, 252)\t0.18471277793166513\n",
      "  (58, 25)\t0.17359710715985818\n",
      "  (58, 182)\t0.21924120508151101\n",
      "  (58, 143)\t0.21924120508151101\n",
      "  (58, 283)\t0.21924120508151101\n",
      "  (58, 7)\t0.21924120508151101\n",
      "  (58, 475)\t0.21924120508151101\n",
      "  (58, 231)\t0.21924120508151101\n",
      "  (58, 320)\t0.21924120508151101\n",
      "  (58, 292)\t0.21924120508151101\n",
      "  (58, 196)\t0.21924120508151101\n"
     ]
    }
   ],
   "source": [
    "reviews=make_reviews('asdfg18**')\n",
    "vector_array=tfidf(reviews)\n",
    "print vector_array\n",
    "#similarity(vector_array, reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condition 1 : reviewer Burstiness (RB) - focused on product\n",
    "\n",
    "(한 제품에 일정 날에 리뷰를 많이남긴 리뷰어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def burst_in_product(min_count, dataframe):\n",
    "    condition1 = []\n",
    "    product_burst = pd.DataFrame({'count' : dataframe.groupby( [ \"pID\", \"rDate\", \"cId\"] ).size()}).reset_index()\n",
    "    suspicious_reviewers = (product_burst[product_burst['count'] >= min_count])['cId']\n",
    "    for reviewer in suspicious_reviewers:\n",
    "        condition1.append(reviewer)\n",
    "    return remove_duplicate_from_list(condition1)\n",
    "\n",
    "def remove_duplicate_from_list(input_list):\n",
    "    tmp_set = set(input_list)\n",
    "    result = list(tmp_set)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condition 2 : reviewer who has a lot of reviews\n",
    "(minimum리뷰수를 적절히 바꿔가면서 리뷰가 많은 리뷰어 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_reviewer_who_has_many_reviews(min_review, dataframe):\n",
    "    condition2 = []\n",
    "    reviewer_and_reviews = dataframe['cId'].value_counts()\n",
    "    suspicious_reviewers = reviewer_and_reviews[reviewer_and_reviews >= min_review].index\n",
    "    for reviewer in suspicious_reviewers:\n",
    "        condition2.append(reviewer)\n",
    "    return condition2\n",
    "\n",
    "#.encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condition 3 : 상호명(아뜨랑스, 고고싱, 스타일난다(난다))를 직접적으로 언급한 리뷰어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewer_who_directly_write_sitename(min_count, dataframe):\n",
    "    condition3 = [] \n",
    "    reviewer_who_write_sitename = dataframe[dataframe['desc'].str.contains(u\"고고싱\")]\n",
    "    reviewer_and_reviews = reviewer_who_write_sitename['cId'].value_counts()\n",
    "    suspicious_reviewers = reviewer_and_reviews[reviewer_and_reviews >= min_count].index\n",
    "    for reviewer in suspicious_reviewers:\n",
    "        condition3.append(reviewer)\n",
    "        \n",
    "    return condition3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condition4 : 평균 rScore가 5에 가까운 리뷰어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewer_who_has_high_rscore(min_rscore, dataframe):\n",
    "    condition4 = [] \n",
    "    mean_rscore = dataframe.groupby(dataframe.cId).mean()['rScore']\n",
    "    suspicious_reviewers = mean_rscore[mean_rscore >= min_rscore].index\n",
    "    for reviewer in suspicious_reviewers:\n",
    "        condition4.append(reviewer)\n",
    "        \n",
    "    return condition4\n",
    "\n",
    "def intersect(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "#spam_reviewers = (intersect(intersect(intersect(condition3, condition4), condition2), condition1))\n",
    "#pprint(spam_reviewers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condition 5 : reviewer who has many reviews in A product over all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewer_who_has_many_reviews_in_a_product(min_count, dataframe):\n",
    "    condition5 = []\n",
    "    product_burst = pd.DataFrame({'count' : dataframe.groupby( [ \"pID\", \"cId\"] ).size()}).reset_index()\n",
    "    suspicious_reviewers = (product_burst[product_burst['count'] >= min_count])['cId']\n",
    "    for reviewer in suspicious_reviewers:\n",
    "        condition5.append(reviewer)\n",
    "    \n",
    "    return remove_duplicate_from_list(condition5)\n",
    "\n",
    "#reviewer_who_has_many_reviews_in_a_product(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reviewer_who_satisfy_some_condition - intersect ver.\n",
    "\n",
    "spammer cId리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "각 bool 파라미터는 각 조건의 포함여부를 나타내며 실험32의 경우 모든 조건을 보므로 다 1임\n",
    "cond1 : 한 제품 & 특정 날짜에 cond1개 초과로 남긴 리뷰어\n",
    "cond2 : cond2개 초과의 리뷰를 가진 리뷰어\n",
    "cond3 : 상호명 언급을 cond3번 초과한 리뷰어\n",
    "cond4 : 평점 cond4초과 리뷰어\n",
    "cond5 : 한제품에 cond5개 초과로 리뷰남긴 리뷰어 추가하기\n",
    "'''\n",
    "def reviewer_who_satisfy_some_condition(dataframe, cond1_bool, cond2_bool, cond3_bool, cond4_bool, cond5_bool,\n",
    "                                        cond1, cond2, cond3, cond4, cond5):\n",
    "    \n",
    "    unique_cid = dataframe.cId.unique()\n",
    "    #condition1\n",
    "    if(cond1_bool == 1):\n",
    "        reviewer1 = burst_in_product(cond1, dataframe)\n",
    "    else:\n",
    "        reviewer1 = unique_cid\n",
    "    \n",
    "    #condition2\n",
    "    if(cond2_bool == 1):\n",
    "        reviewer2 = find_reviewer_who_has_many_reviews(cond2, dataframe)\n",
    "    else:\n",
    "        reviewer2 = unique_cid\n",
    "        \n",
    "    #condition3\n",
    "    if(cond3_bool == 1):\n",
    "        reviewer3 = reviewer_who_directly_write_sitename(cond3, dataframe)\n",
    "    else:\n",
    "        reviewer3 = unique_cid\n",
    "    \n",
    "    #condition4\n",
    "    if(cond4_bool == 1):\n",
    "        reviewer4 = reviewer_who_has_high_rscore(cond4, dataframe)\n",
    "    else:\n",
    "        reviewer4 = unique_cid\n",
    "        \n",
    "    #condition5\n",
    "    if(cond5_bool == 1):\n",
    "        reviewer5 = reviewer_who_has_many_reviews_in_a_product(cond5, dataframe)\n",
    "    else:\n",
    "        reviewer5 = unique_cid\n",
    "        \n",
    "    spam_reviewers = intersect(intersect(intersect(intersect(reviewer1, reviewer2), reviewer3), reviewer4), reviewer5)\n",
    "    \n",
    "    #네이버 페이 구매자는 제외\n",
    "    if(u'\\ub124\\uc774\\ubc84 \\ud398\\uc774 \\uad6c\\ub9e4\\uc790' in spam_reviewers):\n",
    "        spam_reviewers.remove(u'\\ub124\\uc774\\ubc84 \\ud398\\uc774 \\uad6c\\ub9e4\\uc790')\n",
    "    \n",
    "    except_spam_in_gogosing = dataframe[~dataframe.cId.isin(spam_reviewers)]\n",
    "    print(\"<intersect condition>\")\n",
    "    print(\"cond1 =\" + str(cond1) + \", cond2 =\" + str(cond2) + \", cond3 =\" + str(cond3) + \", cond4 =\" + str(cond4) + \", cond5 =\" + str(cond5))\n",
    "    print(\"the number of spam_reviewers : \" + str(len(spam_reviewers)))\n",
    "    print(\"suspicious spammers : \"),\n",
    "    print(spam_reviewers)\n",
    "    print(\"the number of non spam reviewers : \" + str(len(except_spam_in_gogosing.cId.unique())))\n",
    "    rscore = except_spam_in_gogosing['rScore'].value_counts()\n",
    "      \n",
    "    #print(\"except spam in gogosing : \" )\n",
    "    #print(except_spam_in_gogosing)\n",
    "\n",
    "    #어떤 평점의 리뷰가 전체 사라질 경우를 방지하기 위함\n",
    "    if(not(5.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[5.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(4.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[4.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(3.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[3.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(2.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[2.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(1.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[1.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    print(\"rscore : \")\n",
    "    print(rscore)        \n",
    "    \n",
    "    print (\"ratio btw 5.0 and 4.0 : \" + str(float(rscore[5.0])/float(rscore[4.0])))\n",
    "    print (\"ratio btw 5.0 and 3.0 : \" + str(float(rscore[5.0])/float(rscore[3.0])))\n",
    "    print (\"ratio btw 5.0 and 2.0 : \" + str(float(rscore[5.0])/float(rscore[2.0])))\n",
    "    print (\"ratio btw 5.0 and 1.0 : \" + str(float(rscore[5.0])/float(rscore[1.0])))\n",
    "    \n",
    "    print (\"the number of 5.0 reviews : \" + str(rscore[5.0]))\n",
    "    print (\"the number of 4.0 reviews : \" + str(rscore[4.0]))\n",
    "    print (\"the number of 3.0 reviews : \" + str(rscore[3.0]))\n",
    "    print (\"the number of 2.0 reviews : \" + str(rscore[2.0]))\n",
    "    print (\"the number of 1.0 reviews : \" + str(rscore[1.0]))\n",
    "                    \n",
    "    score = ('5.0', '4.0', '3.0', '2.0', '1.0')\n",
    "    number_of_reviews = [rscore[5.0],\n",
    "                     rscore[4.0],\n",
    "                     rscore[3.0],\n",
    "                     rscore[2.0],\n",
    "                     rscore[1.0]]\n",
    "\n",
    "    plt.bar(score, number_of_reviews, color=['red'],\n",
    "        width=0.3, alpha=0.5)\n",
    "    plt.xticks(score, fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylabel('# of review', fontsize=15)\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "    plt.xlabel('rScore', fontsize=15)\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0.0, except_spam_in_gogosing.shape[0]+500])\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n",
    "    return spam_reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  reviewer_who_satisfy_some_condition - union ver.\n",
    "\n",
    "non spammer들의 cId리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewer_who_satisfy_some_condition_union(dataframe, cond1_bool, cond2_bool, cond3_bool, cond4_bool, cond5_bool,\n",
    "                                        cond1, cond2, cond3, cond4, cond5):\n",
    "    \n",
    "     #condition1\n",
    "    if(cond1_bool == 1):\n",
    "        reviewer1 = burst_in_product(cond1, dataframe)\n",
    "    else:\n",
    "        reviewer1 = []\n",
    "    \n",
    "    #condition2\n",
    "    if(cond2_bool == 1):\n",
    "        reviewer2 = find_reviewer_who_has_many_reviews(cond2, dataframe)\n",
    "    else:\n",
    "        reviewer2 = []\n",
    "        \n",
    "    #condition3\n",
    "    if(cond3_bool == 1):\n",
    "        reviewer3 = reviewer_who_directly_write_sitename(cond3, dataframe)\n",
    "    else:\n",
    "        reviewer3 = []\n",
    "    \n",
    "    #condition4\n",
    "    if(cond4_bool == 1):\n",
    "        reviewer4 = reviewer_who_has_high_rscore(cond4, dataframe)\n",
    "    else:\n",
    "        reviewer4 = []\n",
    "        \n",
    "    #condition5\n",
    "    if(cond5_bool == 1):\n",
    "        reviewer5 = reviewer_who_has_many_reviews_in_a_product(cond5, dataframe)\n",
    "    else:\n",
    "        reviewer5 = []  \n",
    "        \n",
    "    spam_reviewers = remove_duplicate_from_list(reviewer1 + reviewer2 + reviewer3 + reviewer4 + reviewer5)\n",
    "    \n",
    "    \n",
    "    #네이버 페이 구매자는 스패머에서 일단 제외\n",
    "    if(u'\\ub124\\uc774\\ubc84 \\ud398\\uc774 \\uad6c\\ub9e4\\uc790' in spam_reviewers):\n",
    "        spam_reviewers.remove(u'\\ub124\\uc774\\ubc84 \\ud398\\uc774 \\uad6c\\ub9e4\\uc790')\n",
    "    \n",
    "    except_spam_in_gogosing = dataframe[~dataframe.cId.isin(spam_reviewers)]\n",
    "    print(\"total number of suspicious spam reviewers : \" + str(len(spam_reviewers)))\n",
    "\n",
    "    print(\"total number of expected non-spam reviewers : \" + str(len(except_spam_in_gogosing.cId.unique()))) \n",
    "    \n",
    "    print(\"<union condition>\")\n",
    "    print(\"cond1 =\" + str(cond1) + \", cond2 =\" + str(cond2) + \", cond3 =\" + str(cond3) + \", cond4 =\" + str(cond4) + \", cond5 =\" + str(cond5))\n",
    "    \n",
    "    rscore = except_spam_in_gogosing['rScore'].value_counts()\n",
    "     \n",
    "\n",
    "    if(not(5.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[5.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(4.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[4.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(3.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[3.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(2.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[2.0])\n",
    "        rscore = rscore.add(add_row)\n",
    "    if(not(1.0 in rscore.index)):\n",
    "        add_row = pd.Series([1], index=[1.0])\n",
    "        rscore = rscore.add(add_row)  \n",
    "    \n",
    "    print (\"ratio btw 5.0 and 4.0 : \" + str(float(rscore[5.0])/float(rscore[4.0])))\n",
    "    print (\"ratio btw 5.0 and 3.0 : \" + str(float(rscore[5.0])/float(rscore[3.0])))\n",
    "    print (\"ratio btw 5.0 and 2.0 : \" + str(float(rscore[5.0])/float(rscore[2.0])))\n",
    "    print (\"ratio btw 5.0 and 1.0 : \" + str(float(rscore[5.0])/float(rscore[1.0])))\n",
    "    \n",
    "\n",
    "    print (\"the number of 5.0 reviews : \" + str(rscore[5.0]))\n",
    "    print (\"the number of 4.0 reviews : \" + str(rscore[4.0]))\n",
    "    print (\"the number of 3.0 reviews : \" + str(rscore[3.0]))\n",
    "    print (\"the number of 2.0 reviews : \" + str(rscore[2.0]))\n",
    "    print (\"the number of 1.0 reviews : \" + str(rscore[1.0]))\n",
    "    \n",
    "                    \n",
    "    score = ('5.0', '4.0', '3.0', '2.0', '1.0')\n",
    "    number_of_reviews = [rscore[5.0],\n",
    "                     rscore[4.0],\n",
    "                     rscore[3.0],\n",
    "                     rscore[2.0],\n",
    "                     rscore[1.0]]\n",
    "\n",
    "    plt.bar(score, number_of_reviews, color=['red'],\n",
    "        width=0.3, alpha=0.5)\n",
    "    plt.xticks(score, fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylabel('# of review', fontsize=15)\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "    plt.xlabel('rScore', fontsize=15)\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0.0, except_spam_in_gogosing.shape[0]+1000])\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    return except_spam_in_gogosing.cId.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_spammer=reviewer_who_satisfy_some_condition_union(go_data, 1, 1, 1, 1, 1, 3, 50, 10, 4.95, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_spammer2=reviewer_who_satisfy_some_condition_union(go_data, 1, 1, 1, 1, 1, 3, 50, 10, 4.96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_spammer3=reviewer_who_satisfy_some_condition_union(go_data, 1, 1, 1, 1, 1, 3, 50, 2, 4.96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(li, columns=['val'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test np.percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li=[1,2,3,4,5,6,7,8,9,10]\n",
    "li.sort(reverse=True)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile(li,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile(li,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile(li,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile(li,[25,50,75]) #제 1 사 분위수, 중앙값, 제 3사 분위수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviewer_who_satisfy_some_condition(go_data, 1, 1, 1, 1, 1, 3, 50, 10, 4.95, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spammer=[u'asdfg18**', u'ghkal04**', u'rladmswl9708**', u'leeliast**', u'rhdms10**', u'sally70**', u'm0928hy**', u'yeji04**', u'sejin1**', u'wlgml13**', u'yjyim**', u'hooming**', u'sy2004**', u'ik35**', u'sosososo**', u'yeon33**', u'loveheart77**', u'wjswldms0**', u'ch**', u'jy03**', u'seoa40**', u'altnr**', u'acua**', u'wertyuio9**', u'chihn19**', u'dekuu12**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(spammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_count=0\n",
    "for i in range(len(spammer)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer[i])\n",
    "    reviews=make_reviews(spammer[i])\n",
    "    if(len(reviews)<2):\n",
    "        continue:\n",
    "    vector_array=tfidf(reviews)\n",
    "    max_cnt=similarity(vector_array, reviews)\n",
    "    max_count+=max_cnt\n",
    "\n",
    "print str('최대 유사도 0.6 이상인 사람 수: ') + str(max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='chihn19**'])[['desc','rScore', 'rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(go_data.loc[go_data['cId']=='chihn19**'])['rScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statistics.median(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max = __builtins__.max\n",
    "max(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li=[3,1,6,2,9,5,0,5,7,4]\n",
    "print(\"print list: \", li)\n",
    "print(\"length list: \", len(li))\n",
    "li.sort(reverse=True)\n",
    "print(\"print sort list: \", li)\n",
    "\n",
    "_max25=int(round(len(li)*0.25))\n",
    "_max75=int(round(len(li)*0.75))\n",
    "print (\"max 25% order : \" , _max25)\n",
    "print(\"max 25% value of list: \", li[_max25-1])\n",
    "print (\"max 75% order: \" , _max75)\n",
    "print(\"max 75% value of list: \", li[_max75-1])\n",
    "\n",
    "result_mid = print_want_val(li, lambda x: np.percentile(li,50)) # 중간값 반환 \n",
    "print (\"median: \", result_mid)\n",
    "result_q1 = print_want_val( li, lambda x: np.percentile(li,25)) # 25%\n",
    "print(\"1st quartile: \", result_q1)\n",
    "result_q3 = print_want_val(li, lambda x: np.percentile(li,75)) #75%\n",
    "print(\"3rd quartile: \", result_q3)                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_groups(_list):\n",
    "    group1=0\n",
    "    group2=0\n",
    "    group3=0\n",
    "    group4=0\n",
    "    group5=0\n",
    "    group6=0\n",
    "    group7=0\n",
    "    group8=0\n",
    "    group9=0\n",
    "    group10=0\n",
    "    \n",
    "    for i in range(len(_list)):\n",
    "        if(_list[i]<0.1):\n",
    "            group1+=1\n",
    "        elif(_list[i]>=0.1 and _list[i]< 0.2):\n",
    "            group2+=1\n",
    "        elif(_list[i] >=0.2 and _list[i]< 0.3):\n",
    "            group3+=1\n",
    "        elif(_list[i] >=0.3 and _list[i]< 0.4):\n",
    "            group4+=1\n",
    "        elif(_list[i]>=0.4 and _list[i]< 0.5):\n",
    "            group5+=1\n",
    "        elif(_list[i]>=0.5 and _list[i] < 0.6):\n",
    "            group6+=1\n",
    "        elif(_list[i]>=0.6 and _list[i] < 0.7):\n",
    "            group7+=1\n",
    "        elif(_list[i]>=0.7 and _list[i]< 0.8):\n",
    "            group8+=1\n",
    "        elif(_list[i]>=0.8 and _list[i]< 0.9):\n",
    "            group9+=1\n",
    "        elif(_list[i]>=0.9):\n",
    "            group10+=1\n",
    "        \n",
    "    groups=[group1, group2, group3, group4, group5, group6,group7,group8,group9,group10 ]\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_want_val(sm_list,used_func):\n",
    "    val=(used_func(sm_list))\n",
    "   \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. 유사도 구하기222222222\n",
    "def similarity(vector_arr,desc):   \n",
    "    sm=[] #한 리뷰어의 리뷰 유사도를 담을 리스트\n",
    "    max_cnt=0 #리뷰 유사도 최대값이 0.9 이상 count\n",
    "    _sum=0\n",
    "    _mid=0\n",
    "    cnt=0\n",
    "    for i in range(len(desc)-1):\n",
    "        srch_vector= vectorize.transform([desc[i]])\n",
    "        for j in range(i+1, len(desc)):\n",
    "            cosine_similar =cosine_similarity(srch_vector, [vector_arr[j]]).flatten()\n",
    "            cosine_similar=short_float(float(cosine_similar))\n",
    "           # print (\"cosine_similar \") + str(i+1) + str(' 번째 리뷰와') + str(j+1) + str(' 번째 리뷰 : ') + str(cosine_similar)\n",
    "            sm.append(cosine_similar)\n",
    "\n",
    "\n",
    "   # pprint(u'유사도 리스트'),;print (sm)\n",
    "\n",
    "    sm.sort(reverse=True)\n",
    "    _min=min(sm)\n",
    "    _mid=statistics.median(sm) # 유사도의 중간값\n",
    "    _max=max(sm)\n",
    "    _sum=sum(sm)\n",
    "\n",
    "    if(_max>=0.9):\n",
    "        max_cnt+=1\n",
    "        \n",
    "    avg= short_float(_sum/len(sm))\n",
    "    \n",
    "    \n",
    "  #  print ('min : ', _min)\n",
    "  #  print ('mid : ', _mid)\n",
    "  #  print('max : ', _max)\n",
    "    print('avg : ', avg)\n",
    "  #  print('num of 1 : ', cnt)\n",
    "    print('# similarity over 0.9 : ', max_cnt)\n",
    "    \n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    유사도 분포도 - 유사도 최대값 , 중간값, 상위 25%(q3), 상위 75%(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_list=[]\n",
    "mid_list=[]\n",
    "q1_list=[]\n",
    "q3_list=[]\n",
    "\n",
    "for i in range(len(spammer)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer[i])\n",
    "    reviews=make_reviews(spammer[i])\n",
    "    if(len(reviews)<2):\n",
    "        continue\n",
    "    vector_array=tfidf(reviews)\n",
    "    sm=similarity(vector_array, reviews)\n",
    "\n",
    "  \n",
    "    result_max= print_want_val(sm, lambda x: np.percentile(sm,100)) # 최대값 반환 \n",
    "    print (\"max: \", result_max)\n",
    "    max_list.append(result_max)\n",
    "    \n",
    "    result_mid = print_want_val(sm, lambda x: np.percentile(sm,50)) # 중간값 반환 \n",
    "    print (\"median: \", result_mid)\n",
    "    mid_list.append(result_mid)\n",
    "    \n",
    "    result_q1 = print_want_val(sm, lambda x: np.percentile(sm,25)) # 25%\n",
    "    print(\"1st quartile: \", result_q1)\n",
    "    q1_list.append(result_q1)\n",
    "    \n",
    "    result_q3 = print_want_val(sm, lambda x: np.percentile(sm,75)) #75%\n",
    "    print(\"3rd quartile: \", result_q3)         \n",
    "    q3_list.append(result_q3)\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "groups_max=make_groups(max_list)\n",
    "groups_mid=make_groups(mid_list)\n",
    "groups_q1=make_groups(q1_list)\n",
    "groups_q3=make_groups(q3_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.arange(len(max_list))\n",
    "y=sorted(max_list)\n",
    "\n",
    "plt.plot(x,y,color='red',marker='o',linestyle='solid')\n",
    "plt.title('max of similarity')\n",
    "plt.xlabel(\"# of reviewer\")\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.arange(len(q3_list))\n",
    "y=sorted(q3_list)\n",
    "\n",
    "plt.plot(x,y,color='red',marker='o',linestyle='solid')\n",
    "plt.title('3rd quartile of similarity')\n",
    "plt.xlabel(\"# of reviewer\")\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.arange(len(mid_list))\n",
    "y=sorted(mid_list)\n",
    "\n",
    "plt.plot(x,y,color='red',marker='o',linestyle='solid')\n",
    "plt.title('median of similarity')\n",
    "plt.xlabel(\"# of reviewer\")\n",
    "plt.ylabel(\"median similarity\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=np.arange(len(q1_list))\n",
    "y=sorted(q1_list)\n",
    "\n",
    "plt.plot(x,y,color='red',marker='o',linestyle='solid')\n",
    "plt.title('1st quartile of similarity')\n",
    "plt.xlabel(\"# of reviewer\")\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_len = print_group(u'해당 그룹별 spammer 수', groups_max, lambda x: x)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups_max, lambda x: float(\"{:.1f}\".format(1.0 * (x) * 100 / len(spammer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_len\n",
    "labels=y\n",
    "\n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('max of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(3,-9), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()\n",
    "\n",
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('max of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,-7), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_len = print_group(u'해당 그룹별 spammer 수', groups_q3, lambda x: x)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups_q3, lambda x: float(\"{:.1f}\".format(1.0 * (x) * 100 / len(spammer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_len\n",
    "labels=y\n",
    "\n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('3rd quartile of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(3,-9), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()\n",
    "\n",
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('3rd quartile of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,-7), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_len = print_group(u'해당 그룹별 spammer 수', groups_mid, lambda x: x)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups_mid, lambda x: float(\"{:.1f}\".format(1.0 * (x) * 100 / len(spammer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_len\n",
    "labels=y\n",
    "\n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('median of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(3,-9), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()\n",
    "\n",
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('meidan of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,-7), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_len = print_group(u'해당 그룹별 spammer 수', groups_q1, lambda x: x)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups_q1, lambda x: float(\"{:.1f}\".format(1.0 * (x) * 100 / len(spammer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_len\n",
    "labels=y\n",
    "\n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('1st quartile of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(3,-9), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()\n",
    "\n",
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('1st quartile of review similarity')\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,-7), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사도 분포도 - 유사도 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group1=[]\n",
    "group2=[]\n",
    "group3=[]\n",
    "group4=[]\n",
    "group5=[]\n",
    "group6=[]\n",
    "group7=[]\n",
    "group8=[]\n",
    "group9=[]\n",
    "group10=[]\n",
    "max_list=[]\n",
    "_max=0\n",
    "\n",
    "for i in range(len(spammer)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer[i])\n",
    "    reviews=make_reviews(spammer[i])\n",
    "    if(len(reviews)<2):\n",
    "        continue\n",
    "    vector_array=tfidf(reviews)\n",
    "    sm=similarity(vector_array, reviews)\n",
    "    _max=max(sm)\n",
    "    max_list.append(_max)\n",
    "    \n",
    "    if(_max<0.1):\n",
    "        group1.append(spammer[i])\n",
    "    elif(_max>=0.1 and _max< 0.2):\n",
    "        group2.append(spammer[i])\n",
    "    elif(_max>=0.2 and _max< 0.3):\n",
    "        group3.append(spammer[i])\n",
    "    elif(_max >=0.3 and _max < 0.4):\n",
    "        group4.append(spammer[i])\n",
    "    elif(_max>=0.4 and _max < 0.5):\n",
    "        group5.append(spammer[i])\n",
    "    elif(_max>=0.5 and _max < 0.6):\n",
    "        group6.append(spammer[i])\n",
    "    elif(_max>=0.6 and _max < 0.7):\n",
    "        group7.append(spammer[i])\n",
    "    elif(_max>=0.7 and _max < 0.8):\n",
    "        group8.append(spammer[i])\n",
    "    elif(_max>=0.8 and _max < 0.9):\n",
    "        group9.append(spammer[i])\n",
    "    elif(_max>=0.9):\n",
    "        group10.append(spammer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.arange(len(max_list))\n",
    "y=sorted(max_list)\n",
    "\n",
    "plt.plot(x,y,color='red',marker='o',linestyle='solid')\n",
    "plt.title('review similarity')\n",
    "plt.xlabel(\"# of reviewer\")\n",
    "plt.ylabel(\"max similarity\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups=[group1, group2, group3, group4, group5, group6,group7,group8,group9,group10 ]\n",
    "result_len = print_group(u'해당 그룹별 spammer 수', groups, len)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups, lambda x: float(\"{:.1f}\".format(1.0 * len(x) * 100 / len(spammer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_len\n",
    "labels=y\n",
    "\n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('group of review similarity')\n",
    "plt.xlabel(\"max similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(3,-9), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('ratio of review similarity')\n",
    "plt.xlabel(\"max similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,-7), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='wertyuio9**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='seoa40**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='asdfg18**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(go_data.loc[go_data['cId']=='asdfg18**'])['rScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='ghkal04**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='leeliast**'])[['desc','rScore', 'rNo', 'rDate']]).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='sally70**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='yjyim**'])[['desc','rScore', 'rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='jy03**'])[['desc','rScore', 'rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='sejin1**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame((go_data.loc[go_data['cId']=='acua**'])[['desc','rScore', 'pID','rNo', 'rDate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviewer_who_satisfy_some_condition(go_data, 1, 1, 1, 1, 1, 3, 50, 10, 4.96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spammer2= [u'ghkal04**', u'rladmswl9708**', u'leeliast**', u'rhdms10**', u'sally70**', u'm0928hy**', u'yeji04**', u'sejin1**', u'wlgml13**', u'asdfg18**', u'hooming**', u'sy2004**', u'ik35**', u'sosososo**', u'yeon33**', u'loveheart77**', u'wjswldms0**', u'ch**', u'jy03**', u'seoa40**', u'altnr**', u'acua**', u'chihn19**', u'dekuu12**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(spammer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group1=[]\n",
    "group2=[]\n",
    "group3=[]\n",
    "group4=[]\n",
    "group5=[]\n",
    "group6=[]\n",
    "group7=[]\n",
    "group8=[]\n",
    "group9=[]\n",
    "group10=[]\n",
    "max=0\n",
    "\n",
    "for i in range(len(spammer2)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer2[i])\n",
    "    reviews=make_reviews(spammer2[i])\n",
    "    if(len(reviews)<2):\n",
    "        continue\n",
    "    vector_array=tfidf(reviews)\n",
    "    max=similarity(vector_array, reviews)\n",
    "    \n",
    "    if(max<0.1):\n",
    "        group1.append(spammer2[i])\n",
    "    elif(max>=0.1 and max< 0.2):\n",
    "        group2.append(spammer2[i])\n",
    "    elif(max>=0.2 and max< 0.3):\n",
    "        group3.append(spammer2[i])\n",
    "    elif(max >=0.3 and max < 0.4):\n",
    "        group4.append(spammer2[i])\n",
    "    elif(max>=0.4 and max < 0.5):\n",
    "        group5.append(spammer2[i])\n",
    "    elif(max>=0.5 and max < 0.6):\n",
    "        group6.append(spammer2[i])\n",
    "    elif(max>=0.6 and max < 0.7):\n",
    "        group7.append(spammer2[i])\n",
    "    elif(max>=0.7 and max < 0.8):\n",
    "        group8.append(spammer2[i])\n",
    "    elif(max>=0.8 and max < 0.9):\n",
    "        group9.append(spammer2[i])\n",
    "    elif(max>=0.9):\n",
    "        group10.append(spammer2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups=[group1, group2, group3, group4, group5, group6,group7,group8,group9,group10 ]\n",
    "result_len = print_group(u'해당 그룹별 spammer 수', groups, len)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups, lambda x: float(\"{:.1f}\".format(1.0 * len(x) * 100 / len(spammer2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_len\n",
    "labels=y\n",
    "\n",
    "    \n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('group of review similarity')\n",
    "plt.xlabel(\"max similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(3,-9), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9 over']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('ratio of review similarity')\n",
    "plt.xlabel(\"max similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,-7), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviewer_who_satisfy_some_condition(go_data, 1, 1, 1, 1, 1, 3, 50, 2, 4.96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spammer3= [u'ghkal04**', u'rladmswl9708**', u'wldwldg**', u'leeliast**', u'rhdms10**', u'sally70**', u'm0928hy**', u'yeji04**', u'gloryn**', u'sestt**', u'dorosy11**', u'wlgml13**', u'rhdecyli**', u'phr9101**', u'asdfg18**', u'diqkdldiqk**', u'hooming**', u'sy2004**', u'qpqlgi**', u'tmfrl123**', u'jhw20**', u'sejin1**', u'ngt**', u'sosososo**', u'yeon33**', u'chdms03**', u'kimminji**', u'loveheart77**', u'qapl44**', u'wjswldms0**', u'ch**', u'jy03**', u'seoa40**', u'altnr**', u'acua**', u'ik35**', u'ekdmsdl07**', u'redgirl4**', u'dev**', u'ans56**', u'chihn19**', u'syndrome12**', u'sjj44**', u'dekuu12**', u'jsh**', u'gmlwls20**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(spammer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(spammer3)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer3[i])\n",
    "    reviews=make_reviews(spammer3[i])\n",
    "    vector_array=tfidf(reviews)\n",
    "    similarity(vector_array, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group1=[]\n",
    "group2=[]\n",
    "group3=[]\n",
    "group4=[]\n",
    "group5=[]\n",
    "group6=[]\n",
    "group7=[]\n",
    "group8=[]\n",
    "group9=[]\n",
    "group10=[]\n",
    "max=0\n",
    "\n",
    "for i in range(len(spammer3)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer3[i])\n",
    "    reviews=make_reviews(spammer3[i])\n",
    "    if(len(reviews)<2):\n",
    "        continue\n",
    "    vector_array=tfidf(reviews)\n",
    "    max=similarity(vector_array, reviews)\n",
    "    \n",
    "    if(max<0.1):\n",
    "        group1.append(spammer3[i])\n",
    "    elif(max>=0.1 and max< 0.2):\n",
    "        group2.append(spammer3[i])\n",
    "    elif(max>=0.2 and max< 0.3):\n",
    "        group3.append(spammer3[i])\n",
    "    elif(max >=0.3 and max < 0.4):\n",
    "        group4.append(spammer3[i])\n",
    "    elif(max>=0.4 and max < 0.5):\n",
    "        group5.append(spammer3[i])\n",
    "    elif(max>=0.5 and max < 0.6):\n",
    "        group6.append(spammer3[i])\n",
    "    elif(max>=0.6 and max < 0.7):\n",
    "        group7.append(spammer3[i])\n",
    "    elif(max>=0.7 and max < 0.8):\n",
    "        group8.append(spammer3[i])\n",
    "    elif(max>=0.8 and max < 0.9):\n",
    "        group9.append(spammer3[i])\n",
    "    elif(max>=0.9):\n",
    "        group10.append(spammer3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_group(title, groups, used_func):\n",
    "    pivot_num = 0.1\n",
    "    save_list = list()\n",
    "\n",
    "    pprint(title)\n",
    "    cur_num = 0.0\n",
    "    for i, group in enumerate(groups):\n",
    "        save_list.append(used_func(group))\n",
    "        print('group ' + str(i + 1) + ' = ' + str(float(\"{:.1f}\".format(cur_num))) + str(' over ') + str(\n",
    "            float(\"{:.1f}\".format(cur_num + pivot_num))) + str(' under : '), save_list[i])\n",
    "        cur_num += pivot_num\n",
    "    print('\\n')\n",
    "\n",
    "    return save_list\n",
    "\n",
    "\n",
    "result_len = print_group(u'해당 그룹별 spammer 수', groups, len)\n",
    "result_ratio = print_group(u'해당 그룹별 spammer 비율', groups, lambda x: float(\"{:.1f}\".format(1.0 * len(x) * 100 / len(spammer3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9~1.0']\n",
    "y=result_len\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='green',marker='o',linestyle='solid')\n",
    "plt.title('group of review similarity')\n",
    "plt.xlabel(\"max similarity\")\n",
    "plt.ylabel(\"number of reviewer\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,2), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[u'0.1 under',u'0.1~0.2',u'0.2~0.3',u'0.3~0.4',u'0.4~0.5',u'0.5~0.6',u'0.6~0.7',u'0.7~0.8',u'0.8~0.9',u'0.9~1.0']\n",
    "y=result_ratio\n",
    "labels=y\n",
    "    \n",
    "plt.plot(x,y,color='blue',marker='o',linestyle='solid')\n",
    "plt.title('ratio of review similarity')\n",
    "plt.xlabel(\"max similarity\")\n",
    "plt.ylabel(\"number of reviewer (%)\")\n",
    "plt.xticks(np.arange(len(x)),x,rotation=45)\n",
    "for label, x_count, y_count in zip(labels, x, y):\n",
    "    plt.annotate(label,\n",
    "                 xy=(x_count, y_count), #label을 데이터포인트에 두되\n",
    "                 xytext=(4,4), # 약간 떨어져 있게\n",
    "                 textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviewer_who_satisfy_some_condition_union(go_data, 1, 1, 1, 1, 1, 3, 50, 10, 4.95, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(non_spammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_spammer=list(non_spammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_spammer[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#네이버 페이 구매자 제외\n",
    "if(u'\\ub124\\uc774\\ubc84 \\ud398\\uc774 \\uad6c\\ub9e4\\uc790' in non_spammer):\n",
    "        non_spammer.remove(u'\\ub124\\uc774\\ubc84 \\ud398\\uc774 \\uad6c\\ub9e4\\uc790')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(non_spammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_count=0\n",
    "one_reviewer=[]\n",
    "for i in range(len(non_spammer)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(non_spammer[i].encode('utf-8'))\n",
    "\n",
    "    reviews=make_reviews(non_spammer[i])\n",
    "    if(len(reviews)<2):\n",
    "        one_reviewer.append(non_spammer[i])\n",
    "        continue\n",
    "    vector_array=tfidf(reviews)\n",
    "    max_cnt=similarity(vector_array, reviews)\n",
    "    max_count+=max_cnt\n",
    "\n",
    "print str('최대 유사도 0.9 이상인 사람 수: ') + str(max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(one_reviewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviewer_who_satisfy_some_condition_union(go_data, 1, 1, 1, 1, 1, 3, 50, 10, 4.96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviewer_who_satisfy_some_condition_union(go_data, 1, 1, 1, 1, 1, 3, 50, 2, 4.96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spammer_desc=[]\n",
    "for i in range(len(spammer)):\n",
    "    spammer_desc.append(make_reviews(spammer[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(spammer_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint (spammer_desc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spammer_desc= [y for x in spammer_desc for y in x]\n",
    "pprint(spammer_desc[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "split_n_desc=[]\n",
    "for i in range(len(spammer_desc)):\n",
    "    split_n_desc+= (twitter.pos(spammer_desc[i], norm=True, stem=True))\n",
    "    \n",
    "    \n",
    "# pos tagging frequencies for split_n_desc\n",
    "k_pos = []\n",
    "k_tag_count = [] \n",
    "for i in split_n_desc:\n",
    "    k_pos.append(i[1])\n",
    "\n",
    "k_pos = list(set(k_pos))\n",
    "\n",
    "k_data = dict(Counter(elem[1] for elem in split_n_desc))\n",
    "\n",
    "n_table= pd.DataFrame(index = ['spammer리뷰 품사'],\n",
    "                     columns = k_pos,\n",
    "                     data = k_data)\n",
    "\n",
    "n_table=n_table.T\n",
    "n_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_table.sort_values(by='spammer리뷰 품사', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
